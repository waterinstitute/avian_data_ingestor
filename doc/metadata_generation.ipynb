{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8112f027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable jedi autocompleter\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddde4dc",
   "metadata": {},
   "source": [
    "# This notebook is the fundation of the Avian Data ingester\n",
    "The ingester component should\n",
    "  - Generate the thumbnail\n",
    "  - Get the EXIF metadata from the image\n",
    "  - Add the dotting information to the image metadata (currently in an MS access database)\n",
    "  - Read the KMZ/KML file with the routes to asign the GPS Location to each of the photos if needed. \n",
    "    <img src=\"./img/AvianDataIngestor.png\" width=800px/>\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6354e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters \n",
    "import ipywidgets as widgets\n",
    "input_path = widgets.Text(\n",
    "    value='/mnt/d/2018',\n",
    "    placeholder='InputData',\n",
    "    description='Input folder (folder containing the jpg images, the dotting database and the KMLs):',\n",
    "    disabled=False\n",
    ")\n",
    "display(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55c7f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "thumbnail_size = (518,345)\n",
    "create_thumbnails = True\n",
    "replace = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1a5e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ExifTags\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "import platform\n",
    "import pandas_access\n",
    "from datetime import datetime\n",
    "import pyodbc\n",
    "\n",
    "# PILlow have methods to read exif, however, in the tests\n",
    "# made, it returns a empty dict for images with actual exif data\n",
    "import piexif\n",
    "import fiona\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import sqlite3\n",
    "import tempfile\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "# enable KML support which is disabled by default\n",
    "fiona.drvsupport.supported_drivers[\"kml\"] = \"r\"\n",
    "fiona.drvsupport.supported_drivers[\"KML\"] = \"r\"\n",
    "\n",
    "\n",
    "def _convert_to_degress(value):\n",
    "    \"\"\"\n",
    "    Helper function to convert the GPS coordinates stored in the EXIF to degress in float format\n",
    "    Borrowed from: https://gist.github.com/snakeye/fdc372dbf11370fe29eb\n",
    "    Modified to recieve a tuple instead of a exifread.utils.Ratio\n",
    "    :param value:\n",
    "    :type value: tuple\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    d = float(value[0][0]) / float(value[0][1])\n",
    "    m = float(value[1][0]) / float(value[1][1])\n",
    "    s = float(value[2][0]) / float(value[2][1])\n",
    "\n",
    "    return d + (m / 60.0) + (s / 3600.0)\n",
    "\n",
    "\n",
    "class DottingInfo:\n",
    "    \"\"\"\n",
    "    Access and use the dotting information\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, add_birds_info=True):\n",
    "        self.__add_info = add_birds_info\n",
    "        self.birds_data = {}\n",
    "        if Path(\"birds_data.json\").exists():\n",
    "            with open(\"birds_data.json\") as _bdf:\n",
    "                self.birds_data = json.load(_bdf)\n",
    "        access_databases_paths = list(input_folder.glob(\"*.accdb\"))\n",
    "        db = None\n",
    "        tables = {}\n",
    "        try:\n",
    "            # I think we can assume we have only one database file per group of photos,\n",
    "            # However, if we have more than one, we can concatenate the values of the tables,\n",
    "            # iif they have the same schema.\n",
    "            for db in access_databases_paths:\n",
    "                schema = pandas_access.read_schema(db)\n",
    "                for table_name in schema:\n",
    "\n",
    "                    _t = pandas_access.read_table(db, table_name)\n",
    "                    if table_name == \"tblColonyNameInfo\":\n",
    "                        table_name = \"tblColonyLocationInfo\"\n",
    "                        d = {\"ColonyUID\": \"ColonyID\"}\n",
    "                        _t.rename(columns=d, inplace=True)\n",
    "                    tables[table_name] = (\n",
    "                        _t\n",
    "                        if not table_name in tables\n",
    "                        else pd.concat([tables[table_name], _t])\n",
    "                    ).drop_duplicates()\n",
    "            data = tables.get(\"tblSpeciesData\")\n",
    "            if data is None:\n",
    "                raise Exception(\n",
    "                    \"Please make sure that the table tblSpeciesData exists in the access database\"\n",
    "                )\n",
    "            data[\"Date\"] = pd.to_datetime(data[\"Date\"])\n",
    "            data.PhotoNumber = data.PhotoNumber.astype(int)\n",
    "            \n",
    "            ### If there is not ColonyID, use the LongVersionColonyUID\n",
    "            # to find the correct value\n",
    "            if tables[\"tblSpeciesData\"].ColonyID.isnull().values.any():\n",
    "                _loc = tables[\"tblColonyLocationInfo\"]\n",
    "                _index = data.ColonyID.isnull()\n",
    "                _view = data.loc[_index]\n",
    "                print(len(_view))\n",
    "                data.loc[_index, \"ColonyID\"] = _view.apply(\n",
    "                    lambda row: _loc.loc[\n",
    "                        _loc.LongVersionColonyUID == str(row.LongVersionColonyUID)\n",
    "                    ].ColonyID.values, axis=1\n",
    "                ).apply(lambda x:x[0] if len(x) else None)\n",
    "                print(data.loc[_index, \"ColonyID\"].unique())\n",
    "            data = (\n",
    "                data.set_index(\"SpeciesCode\")\n",
    "                .join(tables[\"tblSpeciesCodes\"].set_index(\"SpeciesCode\"), how=\"left\")\n",
    "                .reset_index()\n",
    "            )\n",
    "            data = (\n",
    "                data.set_index(\"ColonyID\")\n",
    "                .join(\n",
    "                    tables[\"tblColonyLocationInfo\"].set_index(\"ColonyID\"),\n",
    "                    how=\"left\",\n",
    "                    rsuffix=\"from_colonies\",\n",
    "                )\n",
    "                .reset_index()\n",
    "            )\n",
    "            data = (\n",
    "                data.set_index([\"ColonyID\", \"SpeciesCode\"])\n",
    "                .join(\n",
    "                    tables[\"tblColonySiteNotes\"].set_index([\"ColonyID\", \"SpeciesCode\"]),\n",
    "                    how=\"left\",\n",
    "                    rsuffix=\"_notes\",\n",
    "                    on=[\"ColonyID\", \"SpeciesCode\"],\n",
    "                )\n",
    "                .reset_index()\n",
    "            )\n",
    "\n",
    "            if self.__add_info:\n",
    "                b_info = {\n",
    "                    k: json.dumps(self.__get_data(k))\n",
    "                    for k in data[\"SpeciesName\"].unique()\n",
    "                }\n",
    "                data[\"bird_info\"] = data[\"SpeciesName\"].map(b_info)\n",
    "                data.bird_info = data.bird_info.fillna(\"null\")\n",
    "                with open(Path(\"birds_data.json\"), \"w\") as _jd:\n",
    "                    json.dump(self.birds_data, _jd)\n",
    "            _, self.db_name = tempfile.mkstemp()\n",
    "\n",
    "            con = sqlite3.connect(self.db_name)\n",
    "            data.to_sql(\"merged_data\", con)\n",
    "            cur = con.cursor()\n",
    "            cur.execute(\n",
    "                \"CREATE INDEX find_data ON merged_data (Date, CameraNumber, PhotoNumber);\"\n",
    "            )\n",
    "        except pyodbc.Error as e:\n",
    "            print(e)\n",
    "\n",
    "    def get_info_by_name(self, image_name):\n",
    "        \"\"\"\n",
    "        image_name must be DDMonthYYYYCameraX-Photo#.tiff\n",
    "        \"\"\"\n",
    "        name_re = r\"([0-9]{2}[A-Za-z]+[0-9]{4})\\s*Camera(\\d+)-(?:Photo|)(\\d+)\\.*\"\n",
    "        matches = re.match(name_re, image_name)\n",
    "        if not matches:\n",
    "            # raise Exception(f\"FATAL: The name of the photo {image_name} is not following the expected schema\")\n",
    "            return None\n",
    "        photo_info = matches.groups()\n",
    "        photo_date = datetime.strptime(photo_info[0], \"%d%B%Y\")\n",
    "        # tbl_sd = self.merged_data\n",
    "        data = pd.read_sql_query(\n",
    "            f\"select * from merged_data where Date = '{photo_date}' AND CameraNumber = {photo_info[1]} AND PhotoNumber = {int(photo_info[2])}\",\n",
    "            sqlite3.connect(self.db_name),\n",
    "        )\n",
    "        # tbl_sd.loc[(tbl_sd[\"Date\"] == photo_date) & (tbl_sd[\"CameraNumber\"] == photo_info[1]) &  (tbl_sd[\"PhotoNumber\"] == int(photo_info[2]))]\n",
    "        return data\n",
    "\n",
    "    def __get_data(self, bird_name):\n",
    "        if not bird_name in self.birds_data:\n",
    "            sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "            sparql.setQuery(\n",
    "                \"\"\"\n",
    "               PREFIX rdfs:<http://www.w3.org/2000/01/rdf-schema#> \n",
    "                PREFIX yago:<http://dbpedia.org/class/yago/> \n",
    "                PREFIX owl: <http://www.w3.org/2002/07/owl#> \n",
    "                PREFIX dbo: <http://dbpedia.org/ontology/> \n",
    "                PREFIX umbelrc: <http://umbel.org/umbel/rc/>\n",
    "                PREFIX dbr: <http://dbpedia.org/resource/>\n",
    "\n",
    "                select distinct ?Bird, ?label, ?thumbnail, ?page  where { ?Class rdfs:subClassOf|owl:sameAs yago:Bird101503061 .\n",
    "                {{?Bird a ?Class} UNION  \n",
    "                {?Bird a yago:Bird101503061}UNION\n",
    "{?Bird a umbelrc:Bird} UNION\n",
    "{dbr:List_of_birds_by_common_name dbo:wikiPageWikiLink ?Bird}} \n",
    "                ?Bird rdfs:label ?label .\n",
    "                ?Bird dbo:thumbnail ?thumbnail .\n",
    "                ?page  foaf:primaryTopic ?Bird .\n",
    "                FILTER(REGEX(?label, \"THEBIRDNAME\", \"i\"))\n",
    "                } LIMIT 1\n",
    "            \"\"\".replace(\n",
    "                    \"THEBIRDNAME\", str(bird_name)\n",
    "                )\n",
    "            )\n",
    "            sparql.setReturnFormat(JSON)\n",
    "            results = sparql.query().convert()\n",
    "            b = {}\n",
    "            for result in results[\"results\"][\"bindings\"]:\n",
    "                b[\"bird_thumbnail\"] = result[\"thumbnail\"][\"value\"]\n",
    "                b[\"bird_wikipage\"] = result[\"page\"][\"value\"]\n",
    "                self.birds_data[bird_name] = b\n",
    "        return self.birds_data.get(bird_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11addfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "            \n",
    "class KMLInfo:\n",
    "    \"\"\"\n",
    "    Use KML info to tag images.    \n",
    "    \"\"\"\n",
    "    def __init__(self, kmls_paths):\n",
    "        self.kmldf = None\n",
    "        for kml_file in kmls_paths:\n",
    "            _kmldf = gpd.read_file(kml_file)\n",
    "            if \"name\" in _kmldf:\n",
    "                _kmldf.rename({\"name\":\"Name\"})\n",
    "            self.kmldf = pd.concat([self.kmldf, _kmldf]) if self.kmldf is not None else _kmldf\n",
    "    def get_info_by_name(self, name, change_extension = None)->tuple:\n",
    "        \"\"\"\n",
    "        Get information from the KML files about a give image\n",
    "        params: \n",
    "            - name: image name\n",
    "            - change_extension: extension used in the names stored in the kml files\n",
    "                                None if no change is necessary. \n",
    "        \"\"\"\n",
    "        _sn = name if not change_extension else Path(name).with_suffix(f\".{change_extension}\").name\n",
    "        try:\n",
    "            geom = self.kmldf.loc[self.kmldf.Name.str.replace(\" \",\"\") == _sn.replace(\" \",\"\")].geometry\n",
    "            return geom.values[0] if len(geom)>0 else None\n",
    "        except (AttributeError, KeyError) as e:\n",
    "            print(e)\n",
    "            return None\n",
    "    def fallback(self, name, change_extension = None):\n",
    "        name = name if not change_extension else Path(name).with_suffix(f\".{change_extension}\").name\n",
    "        name_re = r\"(?P<date>[0-9]{2}[A-Za-z]+[0-9]{4})\\s*Camera(?P<camera>\\d+)(?:Card\\d){0,1}-(?:Photo|)(?P<photo>\\d+)\\.*\"\n",
    "        matches_name = re.match(name_re, name).groupdict()\n",
    "#        ndf = self.kmldf.Name.apply(lambda x: pd.Series(re.match(name_re, x).groupdict())) \n",
    "#        _view = self.kmldf.loc[(ndf.date==matches_name[\"date\"]) & (ndf.camera==matches_name[\"camera\"]) & ((ndf.photo.astype(int)-int(matches_name[\"photo\"])).abs()<=10) ].copy()\n",
    "        try:\n",
    "            ndf = self.kmldf.Name.apply(lambda x: pd.Series(re.match(name_re, x).groupdict())) \n",
    "            _view = self.kmldf.loc[(ndf.date==matches_name[\"date\"]) & (ndf.camera==matches_name[\"camera\"]) & ((ndf.photo.astype(int)-int(matches_name[\"photo\"])).abs()<=10) ].copy()\n",
    "            _centroid = _view.to_crs(\"EPSG:3857\").dissolve().geometry.centroid.to_crs(\"EPSG:4326\") .values\n",
    "            return _centroid[-1] if _centroid else None\n",
    "        except (KeyError, AttributeError) as e:\n",
    "            print(e)\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715768f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = Path(input_path.value)\n",
    "access_databases_paths = input_folder.glob(\"*.accdb\")\n",
    "thumb_folder = input_folder.joinpath(\"thumbnails\")\n",
    "thumb_folder.mkdir(exist_ok=True, parents=True)\n",
    "metadata_folder = input_folder.joinpath(\"metadata\") \n",
    "metadata_folder.mkdir(exist_ok=True, parents=True)\n",
    "images = list(input_folder.glob(\"*.jpg\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85583ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "exclude_tags = [\"InterColorProfile\", \"StripOffsets\", \"StripByteCounts\", \"XMLPacket\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a927a622",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotting_info = None\n",
    "try:\n",
    "    dotting_info = DottingInfo()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db7bbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _select_coordinates(point, data, fallback=None):\n",
    "    if point:\n",
    "        return point.coords[0], 'kml_point'\n",
    "    if \"exif\" in data and \"GPSLongitude\" in data.get(\"exif\"):\n",
    "        _exif = data.get(\"exif\")\n",
    "        return  ((-1 if _exif.get(\"GPSLongitudeRef\").decode() == \"W\" else 1)*_exif.get(\"GPSLongitude\"), (-1 if _exif.get(\"GPSLatitudeRef\").decode() == \"S\" else 1) * _exif.get(\"GPSLatitude\"), _exif.get(\"GPSAltitude\", None) ),'exif'\n",
    "    if  \"species_colonies\" in data:\n",
    "        sc_list = data[\"species_colonies\"]\n",
    "        count = len (sc_list)\n",
    "        lat = 0\n",
    "        lon = 0\n",
    "        for col in sc_list:\n",
    "            lat += float(col.get(\"Latitude\") or \"0\")\n",
    "            lon += float(col.get(\"Longitude\") or \"0\")\n",
    "        if lon and lat:\n",
    "            return (lon/count, lat/count, None), 'colonies_average'\n",
    "    if fallback:\n",
    "        return fallback.coords[0], 'kml_fallback'\n",
    "    return None, None\n",
    "class ImageProcessor(object):\n",
    "    def __init__(self, dotting_info, kml_info, metadata_folder,create_thumbnails=True, replace=True):\n",
    "        self.dotting_info =  dotting_info\n",
    "        self.kml_info =kml_info\n",
    "        self.metadata_folder = metadata_folder\n",
    "        self.create_thumbnails = create_thumbnails\n",
    "        self.replace = replace\n",
    "\n",
    "    def __call__(self, image_path):\n",
    "        metadata_file = self.metadata_folder.joinpath(image_path.with_suffix(\".json\").name)\n",
    "        if (not self.replace) and metadata_file.exists():\n",
    "            return metadata_file\n",
    "        with Image.open(image_path) as img:      \n",
    "            thumbnail_name  = image_path.with_suffix(\".png\").name\n",
    "            img_meta = {\"name\": image_path.name, \"thumbnail\": thumbnail_name}\n",
    "            piex = piexif.load(image_path.as_posix())\n",
    "            plain_exif = {}\n",
    "            for k in piex:\n",
    "                if k == \"thumbnail\":\n",
    "                    continue\n",
    "                for exif_id in piex[k]:\n",
    "                    t = ExifTags.TAGS.get(exif_id) if k != \"GPS\" else ExifTags.GPSTAGS.get(exif_id)\n",
    "                    if not t or t in exclude_tags:\n",
    "                        continue\n",
    "                    plain_exif[t] = piex[k][exif_id] if not t in (\"GPSLongitude\", \"GPSLatitude\") else _convert_to_degress(piex[k][exif_id])\n",
    "            img_meta[\"exif\"] = plain_exif\n",
    "            if self.create_thumbnails:\n",
    "                img.thumbnail(thumbnail_size)\n",
    "                img.save(thumb_folder.joinpath(thumbnail_name), \"PNG\")\n",
    "            info = self.dotting_info.get_info_by_name(image_path.name)\n",
    "            if info is not None and not info.empty:\n",
    "                _det_cols = [\"SpeciesCode\", \"SpeciesName\", \"Date\", \"ColonyID\",\"Latitude\", \"Longitude\"]\n",
    "                info = info.drop_duplicates([\"CameraNumber\",\"PhotoNumber\", \"Date\"]+_det_cols)\n",
    "                if \"bird_info\" in info:\n",
    "                    info.bird_info = info.bird_info.apply(json.loads)\n",
    "                    _det_cols.append(\"bird_info\")\n",
    "                 \n",
    "                _a = info.groupby([\"CameraNumber\",\"PhotoNumber\", \"Date\"])[_det_cols].apply(lambda x: x.to_dict('records')).reset_index()\n",
    "                _meta = _a.to_dict(orient=\"records\")[0]\n",
    "                _meta[\"species_colonies\"] = _meta.pop(0)\n",
    "                img_meta.update(_meta)\n",
    "            _point = self.kml_info.get_info_by_name(img_meta.get(\"name\"), change_extension=\"jpg\")\n",
    "            coord, _from = _select_coordinates(_point, img_meta, self.kml_info.fallback(img_meta.get(\"name\"), change_extension=\"jpg\") if not _point else None)\n",
    "            if coord:\n",
    "                img_meta[\"longitude\"] = coord[0]\n",
    "                img_meta[\"latitude\"] = coord[1]\n",
    "                img_meta[\"altitude\"] = coord[2] if len(coord)>2 else 0\n",
    "                img_meta[\"location_from\"] = _from\n",
    "            with open(metadata_file,'w') as _file:\n",
    "                json.dump(img_meta, _file, default=str)\n",
    "            return metadata_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057811d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmls_paths =  input_folder.glob(\"*.kml\")\n",
    "kml_info = KMLInfo(kmls_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d8995a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with Pool(7) as pool:\n",
    "    image_processor = ImageProcessor(dotting_info=dotting_info, create_thumbnails=create_thumbnails, kml_info=kml_info, metadata_folder=metadata_folder, replace=replace)\n",
    "    data = pool.map(image_processor, images)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490da16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(metadata_folder.joinpath(\"all.json\"),\"w\") as _all:\n",
    "    json.dump(data, _all, default=str )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10d09f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3be6256",
   "metadata": {},
   "outputs": [],
   "source": [
    "exifdata = piexif.load(\"25May2021Camera1Card3-10010.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644794b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "piex = exifdata\n",
    "plain_exif = {}\n",
    "for k in piex:\n",
    "    if k == \"thumbnail\":\n",
    "        continue\n",
    "    for exif_id in piex[k]:\n",
    "        t = ExifTags.TAGS.get(exif_id) if k != \"GPS\" else ExifTags.GPSTAGS.get(exif_id)\n",
    "        if not t or t in exclude_tags:\n",
    "            continue\n",
    "        plain_exif[t] = piex[k][exif_id] if not t in (\"GPSLongitude\", \"GPSLatitude\") else _convert_to_degress(piex[k][exif_id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192ef5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_exif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dc6b89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
